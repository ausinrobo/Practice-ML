{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "   T1  T2  T3  T4  T5  T6  T7  T8  T9  T10  T11  T12  T13  T14  T15  T16  T17  \\\n",
      "0 -70 -61 -66 -53 -51 -63 -82 -57 -76  -78  -66  -66  -61  -59  -73  -75  -63   \n",
      "1 -77 -74 -71 -76 -65 -63 -66 -52 -55  -75  -72  -75  -74  -61  -64  -63  -53   \n",
      "2 -53 -38 -55 -66 -62 -62 -65 -70 -62  -52  -56  -53  -66  -68  -72  -60  -68   \n",
      "3 -72 -62 -59 -65 -65 -65 -78 -82 -83  -59  -84  -60  -64  -83  -69  -72  -95   \n",
      "4 -67 -69 -65 -63 -59 -53 -70 -72 -71  -60  -61  -57  -54  -76  -61  -66  -71   \n",
      "\n",
      "   T18 target  \n",
      "0  -77    B37  \n",
      "1  -63    B61  \n",
      "2  -77    A19  \n",
      "3  -73    A22  \n",
      "4  -80    A33  \n",
      "\n",
      "Test Data:\n",
      "   T1  T2  T3  T4  T5  T6  T7  T8  T9  T10  T11  T12  T13  T14  T15  T16  T17  \\\n",
      "0 -76 -83 -70 -66 -64 -72 -64 -69 -60  -76  -83  -78  -81  -81  -81  -70  -60   \n",
      "1 -58 -57 -78 -81 -73 -73 -78 -78 -82  -49  -55  -58  -66  -79  -72  -83  -74   \n",
      "2 -70 -70 -71 -69 -69 -68 -61 -55 -53  -82  -87  -76  -68  -57  -64  -75  -57   \n",
      "3 -71 -61 -56 -56 -61 -60 -68 -66 -72  -58  -55  -56  -58  -62  -61  -59  -64   \n",
      "4 -72 -71 -64 -69 -64 -63 -61 -42 -55  -61  -69  -67  -63  -63  -55  -49  -49   \n",
      "\n",
      "   T18  \n",
      "0  -60  \n",
      "1  -80  \n",
      "2  -70  \n",
      "3  -65  \n",
      "4  -57  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "train_data = pd.read_excel('Task1and2/train.xlsx')\n",
    "test_data = pd.read_excel('Task1and2/test.xlsx')\n",
    "\n",
    "# Inspect the datasets\n",
    "print(\"Training Data:\")\n",
    "print(train_data.head())\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Separate features and target variable from training data\n",
    "X_train = train_data.drop('target', axis=1)\n",
    "y_train = train_data['target']\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply Label Encoding to categorical columns\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Apply the same transformation to test data\n",
    "for col in categorical_cols:\n",
    "    test_data[col] = label_encoders[col].transform(test_data[col])\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "test_data = imputer.transform(test_data)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9706162426880697\n",
      "Random Forest Accuracy: 0.9861243368249217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_split, y_train_split)\n",
    "y_pred_log_reg = log_reg.predict(X_val_split)\n",
    "log_reg_accuracy = accuracy_score(y_val_split, y_pred_log_reg)\n",
    "\n",
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train_split, y_train_split)\n",
    "y_pred_rf = rf_clf.predict(X_val_split)\n",
    "rf_accuracy = accuracy_score(y_val_split, y_pred_rf)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {log_reg_accuracy}\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "test_predictions = rf_clf.predict(test_data)\n",
    "\n",
    "# Load the original test data to get the index\n",
    "original_test_data = pd.read_excel('Task1and2/test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': original_test_data.index, 'Predicted': test_predictions})\n",
    "output.to_csv('Task1and2/test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
